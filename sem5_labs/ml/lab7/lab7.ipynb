{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf83204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "663dbe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_hosteler = 0.60\n",
    "prob_day_scholar = 0.40\n",
    "prob_A_given_hosteler = 0.30\n",
    "prob_A_given_day_scholar = 0.20\n",
    "(prob_hosteler*prob_A_given_hosteler)/((prob_hosteler*prob_A_given_hosteler)+(prob_day_scholar*prob_A_given_day_scholar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12582c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dis=0.01\n",
    "prob_not_dis=0.99\n",
    "prob_pos_dis=0.99\n",
    "prob_pos_no_dis=0.02\n",
    "(prob_dis*prob_pos_dis)/((prob_dis*prob_pos_dis)+((prob_not_dis*prob_pos_no_dis)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0895b397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: yes\n",
      "Probability: 0.8350515463917526\n"
     ]
    }
   ],
   "source": [
    "def fit(X, y):\n",
    "    classes = y.unique()\n",
    "    class_probs = y.value_counts(normalize=True).to_dict()\n",
    "    feature_probs = {}\n",
    "    for feature in X.columns:\n",
    "        feature_probs[feature] = {}\n",
    "        for cls in classes:\n",
    "            subset = X[y == cls]\n",
    "            feature_prob = subset.groupby(feature).size() / subset.shape[0]\n",
    "            feature_probs[feature][cls] = feature_prob.to_dict()\n",
    "    return class_probs, feature_probs, classes\n",
    "\n",
    "def predict(X, class_probs, feature_probs, classes):\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    for _, row in X.iterrows():\n",
    "        class_probs_temp = {}\n",
    "        for cls in classes:\n",
    "            prob = class_probs[cls]\n",
    "            for feature in X.columns:\n",
    "                value = row[feature]\n",
    "                feature_prob = feature_probs.get(feature, {}).get(cls, {}).get(value, 0)\n",
    "                prob *= feature_prob\n",
    "            class_probs_temp[cls] = prob\n",
    "        total_prob = sum(class_probs_temp.values())\n",
    "        if total_prob == 0:\n",
    "            total_prob = 1\n",
    "        class_probs_normalized = {cls: (prob / total_prob) for cls, prob in class_probs_temp.items()}\n",
    "        predicted_class = max(class_probs_normalized, key=class_probs_normalized.get)\n",
    "        predictions.append(predicted_class)\n",
    "        probabilities.append(class_probs_normalized[predicted_class])\n",
    "    return predictions, probabilities\n",
    "\n",
    "data = pd.read_csv('q2.csv')\n",
    "X = data.drop('buys_computer', axis=1)\n",
    "y = data['buys_computer']\n",
    "class_probs, feature_probs, classes = fit(X, y)\n",
    "test_data = pd.DataFrame([{\n",
    "    'age': '<=30',\n",
    "    'income': 'medium',\n",
    "    'student': 'yes',\n",
    "    'credit_rating': 'fair'\n",
    "}])\n",
    "predictions, probabilities = predict(test_data, class_probs, feature_probs, classes)\n",
    "print(f'Prediction: {predictions[0]}')\n",
    "print(f'Probability: {probabilities[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeee0b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: sports\n",
      "Probability: 0.9417083804295171\n"
     ]
    }
   ],
   "source": [
    "def fit(X, y):\n",
    "    classes = y.unique()\n",
    "    class_counts = y.value_counts()\n",
    "    total_count = len(y)\n",
    "    class_probs = {cls: count / total_count for cls, count in class_counts.items()}\n",
    "    word_probs = {cls: {} for cls in classes}\n",
    "    vocabulary = set()\n",
    "    for cls in classes:\n",
    "        subset = X[y == cls]\n",
    "        words = ' '.join(subset).split()\n",
    "        vocabulary.update(words)\n",
    "        word_counts = pd.Series(words).value_counts()\n",
    "        total_words = len(words)\n",
    "        for word in vocabulary:\n",
    "            word_probs[cls][word] = (word_counts.get(word, 0) + 1) / (total_words + len(vocabulary))\n",
    "    return class_probs, word_probs, vocabulary, classes\n",
    "\n",
    "def predict(X, class_probs, word_probs, vocabulary, classes):\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for text in X:\n",
    "        words = text.split()\n",
    "        class_probs_score = {}\n",
    "        for cls in classes:\n",
    "            prob = class_probs[cls]\n",
    "            for word in words:\n",
    "                prob *= word_probs[cls].get(word, 1 / (sum(word_probs[cls].values()) + len(vocabulary)))\n",
    "            class_probs_score[cls] = prob\n",
    "        total_score = sum(class_probs_score.values())\n",
    "        class_probs_normalized = {cls: score / total_score for cls, score in class_probs_score.items()}\n",
    "        predicted_class = max(class_probs_normalized, key=class_probs_normalized.get)\n",
    "        predictions.append(predicted_class)\n",
    "        confidences.append(class_probs_normalized[predicted_class])\n",
    "    return predictions, confidences\n",
    "\n",
    "df = pd.read_csv(\"q3.csv\")\n",
    "class_probs, word_probs, vocabulary, classes = fit(df['text'], df['tag'])\n",
    "y_true = df['tag']\n",
    "y_pred, confidences = predict(df['text'], class_probs, word_probs, vocabulary, classes)\n",
    "test_sentence = [\"A very close game\"]\n",
    "predicted_tag, confidence = predict(test_sentence, class_probs, word_probs, vocabulary, classes)\n",
    "print(f'Prediction: {predicted_tag[0]}')\n",
    "print(f'Probability: {confidence[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48242d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
