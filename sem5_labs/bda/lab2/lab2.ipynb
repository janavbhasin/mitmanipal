{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f33b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum as spark_sum\n",
    "from pyspark.sql.functions import avg as spark_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdae874a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8bd194",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path='/home/lplab/Desktop/janav_220962049/annual-enterprise-survey-2023-financial-year-provisional.csv'\n",
    "df = spark.read.csv(\n",
    "    csv_file_path, \n",
    "    header=True, \n",
    "    inferSchema=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ad283",
   "metadata": {},
   "source": [
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36678298",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.filter(df.Year == 2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dd1d5e",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96e02706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count is 4635\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+-------------+--------------------+-------+----------------------+\n",
      "|Year|Industry_aggregation_NZSIOC|Industry_code_NZSIOC|Industry_name_NZSIOC|             Units|Variable_code|Variable_name|   Variable_category|  Value|Industry_code_ANZSIC06|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+-------------+--------------------+-------+----------------------+\n",
      "|2013|                    Level 1|               99999|      All industries|Dollars (millions)|          H01| Total income|Financial perform...|541,042|  ANZSIC06 division...|\n",
      "+----+---------------------------+--------------------+--------------------+------------------+-------------+-------------+--------------------+-------+----------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('count is',filtered_df.count())\n",
    "filtered_df.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ddc08b",
   "metadata": {},
   "source": [
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a0c04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9330255\n",
      "2013.0\n"
     ]
    }
   ],
   "source": [
    "sum_age = filtered_df.agg(spark_sum(\"Year\").alias(\"total_age\")).collect()[0][\"total_age\"]\n",
    "print(sum_age)\n",
    "sum_age = filtered_df.agg(spark_avg(\"Year\").alias(\"total_age\")).collect()[0][\"total_age\"]\n",
    "print(sum_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd13f9d",
   "metadata": {},
   "source": [
    "Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78a1afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.write \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .save(\"filtered_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28f21f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d902e24",
   "metadata": {},
   "source": [
    "Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bb41f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lplab/anaconda3/lib/python3.7/site-packages/pyspark/context.py:317: FutureWarning: Python 3.7 support is deprecated in Spark 3.4.\n",
      "  warnings.warn(\"Python 3.7 support is deprecated in Spark 3.4.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey: 2\n",
      "hi: 2\n",
      "hello: 3\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "if SparkContext._active_spark_context is not None:\n",
    "    SparkContext._active_spark_context.stop()\n",
    "conf = SparkConf().setAppName(\"WordCount\")\n",
    "sc = SparkContext(conf=conf)\n",
    "text_file = sc.textFile(\"input.txt\")\n",
    "counts = (text_file\n",
    "          .flatMap(lambda line: line.split(\" \"))\n",
    "          .map(lambda word: (word, 1))\n",
    "          .reduceByKey(lambda a, b: a + b))\n",
    "for (word, count) in counts.collect():\n",
    "    print(f\"{word}: {count}\")\n",
    "sc.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
